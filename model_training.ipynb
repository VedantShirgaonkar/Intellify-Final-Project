{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "11371998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, TimeDistributed, Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "454d00af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b6efd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "06b943e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a6df4d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([face, lh, rh])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "21f187b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/smayan/Desktop/ASL/dataset/SL'\n",
    "sequence_length = 30\n",
    "min_sequences_per_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e043d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\n",
    "    'a', 'about', 'again', 'all', 'also', 'always', 'and', 'angry', 'animal', 'answer', \n",
    "    'apple', 'ask', 'baby', 'bad', 'bathroom', 'beautiful', 'because', 'bed', 'before', \n",
    "    'big', 'book', 'boy', 'brother', 'but', 'buy', 'bye', 'call', 'can', 'car', 'cat', \n",
    "    'city', 'class', 'clean', 'clothes', 'cold', 'college', 'color', 'come', 'computer', \n",
    "    'cook', 'dad', 'day', 'deaf', 'different', 'doctor', 'dog', 'done', \"don't want\", \n",
    "    'down', 'drink', 'eat', 'eight', 'enough', 'family', 'fast', 'father', 'feel', \n",
    "    'find', 'fine', 'finish', 'first', 'five', 'food', 'for', 'four', 'friend', 'from', \n",
    "    'get', 'girl', 'give', 'go', 'good', 'goodbye', 'happy', 'hard', 'have', \n",
    "    'head', 'hearing', 'hello', 'help', 'her', 'here', 'home', 'hospital', 'hot', \n",
    "    'house', 'how', 'hungry', 'i', 'if', 'in', 'know', 'language', 'last', 'later', \n",
    "    'learn', 'letter', 'like', 'little bit', 'live', 'look at', 'love', 'make', 'man', \n",
    "    'many', 'me', 'meet', 'milk', 'mom', 'money', 'month', 'more', 'morning', 'mother', \n",
    "    'movie', 'music', 'my', 'name', 'need', 'never', 'new', 'nice', 'night', 'nine', \n",
    "    'no', 'not', 'now', 'old', 'on', 'one', 'open', 'orange', 'our', 'out', 'people', \n",
    "    'phone', 'play', 'please', 'put', 'question', 'read', 'ready', 'red', 'right', 'sad', \n",
    "    'same', 'say', 'school', 'see', 'seven', 'she', 'shirt', 'shoes', 'show', 'sick', \n",
    "    'sign', 'sign language', 'sister', 'sit', 'six', 'sleep', 'slow', 'small', 'sorry', \n",
    "    'stand', 'start', 'stop', 'store', 'story', 'student', 'study', 'talk', 'teach', \n",
    "    'teacher', 'tell', 'ten', 'thank you', 'that']\n",
    "# 'the', 'their', 'they', 'thing', \n",
    "#     'think', 'thirsty', 'this', 'three', 'time', 'tired', 'to', 'today', 'tomorrow', \n",
    "#     'two', 'understand', 'up', 'use', 'wait', 'walk', 'want', 'water', 'way', \n",
    "#     'we', 'wear', 'week', 'what', 'when', 'where', 'which', 'white', 'who', 'why', \n",
    "#     'will', 'with', 'woman', 'word', 'work', 'world', 'write', 'wrong', 'year', 'yellow', \n",
    "#     'yes', 'yesterday', 'you', 'your'\n",
    "# ]\n",
    "label_map = {label: num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22686414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "57fc233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b99241aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('/media/smayan/500GB SSD/X.npy')\n",
    "y = np.load('/media/smayan/500GB SSD/y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "82c6ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.shape[2]\n",
    "X = X.reshape(X.shape[0], X.shape[1], num_features, 1)\n",
    "\n",
    "y_categorical = to_categorical(y, num_classes=len(actions))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_categorical, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f2264757",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.squeeze(-1)  # Now shape = (6314, 30, 1530)\n",
    "X_test  = X_test.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "51056d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7893, 30, 1530, 1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f5ff6911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6314, 30, 1530)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "821d602e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights computed: {0: 1.7054883318928262, 1: 1.0312255030049646, 2: 0.8868539325842697, 3: 0.9639716658524671, 4: 1.007788559754852, 5: 0.9238061797752809, 6: 1.4780898876404494, 7: 1.0557784911717496, 8: 0.7779420461265524, 9: 1.0312255030049646, 10: 0.6821953327571305, 11: 1.007788559754852, 12: 0.8062308478038815, 13: 0.8868539325842697, 14: 1.0815291860783776, 15: 1.1369922212618842, 16: 0.9434616304087975, 17: 0.6821953327571305, 18: 0.5992256301245066, 19: 0.6074342004001847, 20: 1.4780898876404494, 21: 1.0557784911717496, 22: 0.715204784342153, 23: 1.4780898876404494, 24: 0.9049529924329283, 25: 1.4780898876404494, 26: 0.726929452937926, 27: 0.8366546533813864, 28: 1.0557784911717496, 29: 0.8062308478038815, 30: 0.7918338683788122, 31: 0.7918338683788122, 32: 0.9049529924329283, 33: 1.4780898876404494, 34: 0.6618312929733355, 35: 0.9853932584269663, 36: 0.9049529924329283, 37: 1.2317415730337078, 38: 0.5156127515024823, 39: 0.9434616304087975, 40: 1.2317415730337078, 41: 0.8211610486891385, 42: 0.7645292522278186, 43: 0.8366546533813864, 44: 0.6618312929733355, 45: 0.6718590398365679, 46: 1.8476123595505618, 47: 1.2317415730337078, 48: 0.9238061797752809, 49: 0.503894279877426, 50: 1.0557784911717496, 51: 1.2669341894060995, 52: 1.4780898876404494, 53: 0.6618312929733355, 54: 1.1085674157303371, 55: 1.2317415730337078, 56: 0.9049529924329283, 57: 0.9049529924329283, 58: 0.8366546533813864, 59: 1.3857092696629214, 60: 1.0557784911717496, 61: 1.5836677367576244, 62: 1.0557784911717496, 63: 2.333826138379657, 64: 1.642322097378277, 65: 1.0557784911717496, 66: 0.9853932584269663, 67: 0.8527441659464131, 68: 0.8366546533813864, 69: 0.7918338683788122, 70: 0.5096861681518792, 71: 0.8366546533813864, 72: 1.430409568684306, 73: 0.9434616304087975, 74: 1.642322097378277, 75: 1.430409568684306, 76: 1.0815291860783776, 77: 0.9853932584269663, 78: 2.2171348314606742, 79: 0.5758791770027725, 80: 1.1669130691898284, 81: 1.0557784911717496, 82: 1.0815291860783776, 83: 1.1669130691898284, 84: 0.7390449438202247, 85: 1.007788559754852, 86: 0.9853932584269663, 87: 1.430409568684306, 88: 1.7737078651685394, 89: 1.2317415730337078, 90: 1.2669341894060995, 91: 0.9238061797752809, 92: 0.6928546348314607, 93: 0.8366546533813864, 94: 0.6158707865168539, 95: 0.9639716658524671, 96: 0.8527441659464131, 97: 0.715204784342153, 98: 2.608393919365499, 99: 1.007788559754852, 100: 4.4342696629213485, 101: 1.0815291860783776, 102: 0.715204784342153, 103: 0.726929452937926, 104: 0.8062308478038815, 105: 1.8476123595505618, 106: 0.7515711293087031, 107: 1.3041969596827494, 108: 0.9853932584269663, 109: 1.1369922212618842, 110: 1.1984512602490132, 111: 0.9853932584269663, 112: 1.2317415730337078, 113: 0.642647777234978, 114: 1.5290585044556373, 115: 0.9238061797752809, 116: 1.4780898876404494, 117: 1.1984512602490132, 118: 1.0557784911717496, 119: 1.0557784911717496, 120: 0.9639716658524671, 121: 1.4780898876404494, 122: 1.5290585044556373, 123: 1.7737078651685394, 124: 0.6821953327571305, 125: 1.2317415730337078, 126: 0.9434616304087975, 127: 1.1369922212618842, 128: 1.2317415730337078, 129: 1.1984512602490132, 130: 1.1085674157303371, 131: 0.7038523274478331, 132: 1.9279433317049341, 133: 1.7054883318928262, 134: 0.9639716658524671, 135: 1.642322097378277, 136: 0.715204784342153, 137: 1.0815291860783776, 138: 1.3437180796731358, 139: 1.2669341894060995, 140: 1.3041969596827494, 141: 0.8366546533813864, 142: 1.1085674157303371, 143: 0.8694646397884996, 144: 1.0312255030049646, 145: 0.8694646397884996, 146: 1.0312255030049646, 147: 0.8868539325842697, 148: 1.8476123595505618, 149: 1.3857092696629214, 150: 1.2317415730337078, 151: 0.6520984798413747, 152: 1.3041969596827494, 153: 0.8694646397884996, 154: 0.7515711293087031, 155: 0.9238061797752809, 156: 1.4780898876404494, 157: 0.9853932584269663, 158: 1.5836677367576244, 159: 1.430409568684306, 160: 1.3437180796731358, 161: 0.9049529924329283, 162: 0.9853932584269663, 163: 1.0312255030049646, 164: 1.430409568684306, 165: 1.642322097378277, 166: 1.7054883318928262, 167: 1.0312255030049646, 168: 1.0815291860783776, 169: 0.9238061797752809, 170: 0.7515711293087031, 171: 1.3041969596827494, 172: 1.0557784911717496, 173: 0.8527441659464131, 174: 0.6928546348314607, 175: 1.3437180796731358, 176: 1.0557784911717496, 177: 2.111556982343499}\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(f\"Class weights computed: {class_weight_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "908e16ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smayan/Desktop/AI-ML-DS/AI-and-ML-Course/.conda/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(256, kernel_size=3, activation='relu', input_shape=(sequence_length, 1530)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(128)))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(len(actions), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1a796af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = f'logs/wsl_model_{timestamp}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "677d1713",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "66e8fc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,175,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_12                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,624</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_13                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">656,384</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">45,746</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │     \u001b[38;5;34m1,175,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_12                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m1,050,624\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_13                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m656,384\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m178\u001b[0m)            │        \u001b[38;5;34m45,746\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,994,866</span> (11.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,994,866\u001b[0m (11.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,994,354</span> (11.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,994,354\u001b[0m (11.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "22367f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6314, 30, 1530)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "17035fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-7)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "263b751e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9310 - loss: 0.2053 - val_accuracy: 0.6852 - val_loss: 1.3176 - learning_rate: 2.0000e-04\n",
      "Epoch 2/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9538 - loss: 0.1558 - val_accuracy: 0.6529 - val_loss: 1.4719 - learning_rate: 2.0000e-04\n",
      "Epoch 3/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9536 - loss: 0.1544 - val_accuracy: 0.6935 - val_loss: 1.2754 - learning_rate: 2.0000e-04\n",
      "Epoch 4/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9532 - loss: 0.1517 - val_accuracy: 0.7283 - val_loss: 1.1537 - learning_rate: 2.0000e-04\n",
      "Epoch 5/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9515 - loss: 0.1604 - val_accuracy: 0.7492 - val_loss: 1.0826 - learning_rate: 2.0000e-04\n",
      "Epoch 6/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9482 - loss: 0.1616 - val_accuracy: 0.7118 - val_loss: 1.2521 - learning_rate: 2.0000e-04\n",
      "Epoch 7/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9514 - loss: 0.1560 - val_accuracy: 0.7676 - val_loss: 1.0264 - learning_rate: 2.0000e-04\n",
      "Epoch 8/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9556 - loss: 0.1449 - val_accuracy: 0.6276 - val_loss: 1.7110 - learning_rate: 2.0000e-04\n",
      "Epoch 9/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9482 - loss: 0.1649 - val_accuracy: 0.5763 - val_loss: 1.8350 - learning_rate: 2.0000e-04\n",
      "Epoch 10/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9530 - loss: 0.1540 - val_accuracy: 0.6491 - val_loss: 1.5036 - learning_rate: 2.0000e-04\n",
      "Epoch 11/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9507 - loss: 0.1607 - val_accuracy: 0.6263 - val_loss: 1.5941 - learning_rate: 2.0000e-04\n",
      "Epoch 12/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9545 - loss: 0.1464 - val_accuracy: 0.6346 - val_loss: 1.5950 - learning_rate: 2.0000e-04\n",
      "Epoch 13/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9591 - loss: 0.1376 - val_accuracy: 0.6593 - val_loss: 1.4722 - learning_rate: 2.0000e-04\n",
      "Epoch 14/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9486 - loss: 0.1586 - val_accuracy: 0.6225 - val_loss: 1.6316 - learning_rate: 2.0000e-04\n",
      "Epoch 15/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9495 - loss: 0.1490 - val_accuracy: 0.6314 - val_loss: 1.7187 - learning_rate: 2.0000e-04\n",
      "Epoch 16/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9630 - loss: 0.1244 - val_accuracy: 0.6206 - val_loss: 1.7048 - learning_rate: 2.0000e-04\n",
      "Epoch 17/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9565 - loss: 0.1417 - val_accuracy: 0.6827 - val_loss: 1.4138 - learning_rate: 2.0000e-04\n",
      "Epoch 18/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9527 - loss: 0.1354 - val_accuracy: 0.7878 - val_loss: 0.9956 - learning_rate: 4.0000e-05\n",
      "Epoch 19/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9526 - loss: 0.1491 - val_accuracy: 0.7479 - val_loss: 1.1449 - learning_rate: 4.0000e-05\n",
      "Epoch 20/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9643 - loss: 0.1261 - val_accuracy: 0.7929 - val_loss: 0.9428 - learning_rate: 4.0000e-05\n",
      "Epoch 21/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9656 - loss: 0.1198 - val_accuracy: 0.7878 - val_loss: 0.9486 - learning_rate: 4.0000e-05\n",
      "Epoch 22/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9601 - loss: 0.1332 - val_accuracy: 0.7935 - val_loss: 0.9296 - learning_rate: 4.0000e-05\n",
      "Epoch 23/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9654 - loss: 0.1123 - val_accuracy: 0.7986 - val_loss: 0.9210 - learning_rate: 4.0000e-05\n",
      "Epoch 24/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9587 - loss: 0.1336 - val_accuracy: 0.7878 - val_loss: 0.9352 - learning_rate: 4.0000e-05\n",
      "Epoch 25/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9576 - loss: 0.1357 - val_accuracy: 0.7910 - val_loss: 0.9445 - learning_rate: 4.0000e-05\n",
      "Epoch 26/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9556 - loss: 0.1371 - val_accuracy: 0.7859 - val_loss: 0.9334 - learning_rate: 4.0000e-05\n",
      "Epoch 27/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9626 - loss: 0.1178 - val_accuracy: 0.7948 - val_loss: 0.9298 - learning_rate: 4.0000e-05\n",
      "Epoch 28/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9648 - loss: 0.1105 - val_accuracy: 0.7954 - val_loss: 0.9261 - learning_rate: 4.0000e-05\n",
      "Epoch 29/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9610 - loss: 0.1243 - val_accuracy: 0.7891 - val_loss: 0.9359 - learning_rate: 4.0000e-05\n",
      "Epoch 30/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9640 - loss: 0.1157 - val_accuracy: 0.8024 - val_loss: 0.9112 - learning_rate: 4.0000e-05\n",
      "Epoch 31/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9631 - loss: 0.1177 - val_accuracy: 0.7954 - val_loss: 0.9330 - learning_rate: 4.0000e-05\n",
      "Epoch 32/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9594 - loss: 0.1320 - val_accuracy: 0.7999 - val_loss: 0.9201 - learning_rate: 4.0000e-05\n",
      "Epoch 33/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9641 - loss: 0.1106 - val_accuracy: 0.7961 - val_loss: 0.9595 - learning_rate: 4.0000e-05\n",
      "Epoch 34/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9625 - loss: 0.1126 - val_accuracy: 0.7999 - val_loss: 0.9365 - learning_rate: 4.0000e-05\n",
      "Epoch 35/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9582 - loss: 0.1290 - val_accuracy: 0.7859 - val_loss: 0.9513 - learning_rate: 4.0000e-05\n",
      "Epoch 36/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9660 - loss: 0.1109 - val_accuracy: 0.7847 - val_loss: 0.9399 - learning_rate: 4.0000e-05\n",
      "Epoch 37/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9711 - loss: 0.0961 - val_accuracy: 0.7910 - val_loss: 0.9465 - learning_rate: 4.0000e-05\n",
      "Epoch 38/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9707 - loss: 0.1057 - val_accuracy: 0.7923 - val_loss: 0.9070 - learning_rate: 4.0000e-05\n",
      "Epoch 39/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9672 - loss: 0.1054 - val_accuracy: 0.7891 - val_loss: 0.9459 - learning_rate: 4.0000e-05\n",
      "Epoch 40/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9709 - loss: 0.0952 - val_accuracy: 0.7980 - val_loss: 0.9232 - learning_rate: 4.0000e-05\n",
      "Epoch 41/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9687 - loss: 0.1001 - val_accuracy: 0.7796 - val_loss: 0.9956 - learning_rate: 4.0000e-05\n",
      "Epoch 42/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9634 - loss: 0.1180 - val_accuracy: 0.7910 - val_loss: 0.9536 - learning_rate: 4.0000e-05\n",
      "Epoch 43/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9630 - loss: 0.1081 - val_accuracy: 0.7840 - val_loss: 0.9621 - learning_rate: 4.0000e-05\n",
      "Epoch 44/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9686 - loss: 0.0998 - val_accuracy: 0.7593 - val_loss: 1.0321 - learning_rate: 4.0000e-05\n",
      "Epoch 45/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9630 - loss: 0.1146 - val_accuracy: 0.7904 - val_loss: 0.9438 - learning_rate: 4.0000e-05\n",
      "Epoch 46/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9694 - loss: 0.1039 - val_accuracy: 0.8043 - val_loss: 0.9121 - learning_rate: 4.0000e-05\n",
      "Epoch 47/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9693 - loss: 0.1000 - val_accuracy: 0.7973 - val_loss: 0.9203 - learning_rate: 4.0000e-05\n",
      "Epoch 48/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9638 - loss: 0.1123 - val_accuracy: 0.7923 - val_loss: 0.9793 - learning_rate: 4.0000e-05\n",
      "Epoch 49/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9681 - loss: 0.1100 - val_accuracy: 0.7986 - val_loss: 0.9255 - learning_rate: 8.0000e-06\n",
      "Epoch 50/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9715 - loss: 0.0976 - val_accuracy: 0.8037 - val_loss: 0.9097 - learning_rate: 8.0000e-06\n",
      "Epoch 51/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9638 - loss: 0.1299 - val_accuracy: 0.7980 - val_loss: 0.9229 - learning_rate: 8.0000e-06\n",
      "Epoch 52/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9655 - loss: 0.1136 - val_accuracy: 0.7992 - val_loss: 0.9169 - learning_rate: 8.0000e-06\n",
      "Epoch 53/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9672 - loss: 0.1025 - val_accuracy: 0.8011 - val_loss: 0.9118 - learning_rate: 8.0000e-06\n",
      "Epoch 54/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9647 - loss: 0.1122 - val_accuracy: 0.8018 - val_loss: 0.9121 - learning_rate: 8.0000e-06\n",
      "Epoch 55/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9633 - loss: 0.1144 - val_accuracy: 0.7999 - val_loss: 0.9163 - learning_rate: 8.0000e-06\n",
      "Epoch 56/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9692 - loss: 0.1099 - val_accuracy: 0.8030 - val_loss: 0.9118 - learning_rate: 8.0000e-06\n",
      "Epoch 57/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9626 - loss: 0.1129 - val_accuracy: 0.8030 - val_loss: 0.9141 - learning_rate: 8.0000e-06\n",
      "Epoch 58/150\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9689 - loss: 0.1021 - val_accuracy: 0.8030 - val_loss: 0.9144 - learning_rate: 8.0000e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=150,\n",
    "    batch_size=128,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "44a5c55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.9070\n",
      "Test Accuracy: 79.23%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d2a1f0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved as wsl_model_20250819-203608.h5\n"
     ]
    }
   ],
   "source": [
    "model.save(f'main_wsl_model_{timestamp}.h5')\n",
    "print(f\"\\nModel saved as wsl_model_{timestamp}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee576bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11371998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-23 11:19:37.229424: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-23 11:19:37.236261: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755928177.244292  159375 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755928177.246821  159375 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755928177.253076  159375 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755928177.253084  159375 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755928177.253085  159375 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755928177.253086  159375 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-23 11:19:37.255350: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, TimeDistributed, Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "454d00af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6efd2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06b943e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6df4d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([ lh, rh])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21f187b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/smayan/Desktop/ASL/dataset/SL'\n",
    "sequence_length = 30\n",
    "min_sequences_per_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e043d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actions = [\n",
    "#     'a', 'about', 'again', 'all', 'also', 'always', 'and', 'angry', 'animal', 'answer', \n",
    "#     'apple', 'ask', 'baby', 'bad', 'bathroom', 'beautiful', 'because', 'bed', 'before', \n",
    "#     'big', 'book', 'boy', 'brother', 'but', 'buy', 'bye', 'call', 'can', 'car', 'cat', \n",
    "#     'city', 'class', 'clean', 'clothes', 'cold', 'college', 'color', 'come', 'computer', \n",
    "#     'cook', 'dad', 'day', 'deaf', 'different', 'doctor', 'dog', 'done', \"don't want\", \n",
    "#     'down', 'drink', 'eat', 'eight', 'enough', 'family', 'fast', 'father', 'feel', \n",
    "#     'find', 'fine', 'finish', 'first', 'five', 'food', 'for', 'four', 'friend', 'from', \n",
    "#     'get', 'girl', 'give', 'go', 'good', 'goodbye', 'happy', 'hard', 'have', \n",
    "#     'head', 'hearing', 'hello', 'help', 'her', 'here', 'home', 'hospital', 'hot', \n",
    "#     'house', 'how', 'hungry', 'i', 'if', 'in', 'know', 'language', 'last', 'later', \n",
    "#     'learn', 'letter', 'like', 'little bit', 'live', 'look at', 'love', 'make', 'man', \n",
    "#     'many', 'me', 'meet', 'milk', 'mom', 'money', 'month', 'more', 'morning', 'mother', \n",
    "#     'movie', 'music', 'my', 'name', 'need', 'never', 'new', 'nice', 'night', 'nine', \n",
    "#     'no', 'not', 'now', 'old', 'on', 'one', 'open', 'orange', 'our', 'out', 'people', \n",
    "#     'phone', 'play', 'please', 'put', 'question', 'read', 'ready', 'red', 'right', 'sad', \n",
    "#     'same', 'say', 'school', 'see', 'seven', 'she', 'shirt', 'shoes', 'show', 'sick', \n",
    "#     'sign', 'sign language', 'sister', 'sit', 'six', 'sleep', 'slow', 'small', 'sorry', \n",
    "#     'stand', 'start', 'stop', 'store', 'story', 'student', 'study', 'talk', 'teach', \n",
    "#     'teacher', 'tell', 'ten', 'thank you', 'that']\n",
    "# # 'the', 'their', 'they', 'thing', \n",
    "# #     'think', 'thirsty', 'this', 'three', 'time', 'tired', 'to', 'today', 'tomorrow', \n",
    "# #     'two', 'understand', 'up', 'use', 'wait', 'walk', 'want', 'water', 'way', \n",
    "# #     'we', 'wear', 'week', 'what', 'when', 'where', 'which', 'white', 'who', 'why', \n",
    "# #     'will', 'with', 'woman', 'word', 'work', 'world', 'write', 'wrong', 'year', 'yellow', \n",
    "# #     'yes', 'yesterday', 'you', 'your'\n",
    "# # ]\n",
    "# label_map = {label: num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d7eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = ['hello', 'student','i','bye','goodbye','college','wrong','how', 'work', 'your', 'want', 'nice', 'to', 'meet', 'doctor', 'time', 'age', 'breakfast', 'sorry', 'love']\n",
    "label_map = {label: num for num, label in enumerate(actions)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22686414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57fc233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7801fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv.VideoCapture('/home/smayan/Desktop/ASL/dataset/SL/wood/63723.mp4')\n",
    "# with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "#     while cap.isOpened():\n",
    "\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             print(\"Video ended or cannot read the frame.\")\n",
    "#             break\n",
    "\n",
    "#         image, results = mediapipe_detection(frame, holistic)\n",
    "            \n",
    "\n",
    "#         draw_styled_landmarks(image, results)\n",
    "\n",
    "#         cv.imshow('OpenCV feed', image)\n",
    "#         if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "# cap.release()\n",
    "# cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b99241aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('/media/smayan/500GB SSD/X_augment_min.npy')\n",
    "y = np.load('/media/smayan/500GB SSD/y_augment_min.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "853036dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1642, 30, 126)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb739f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1642,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82c6ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.shape[2]\n",
    "X = X.reshape(X.shape[0], X.shape[1], num_features, 1)\n",
    "\n",
    "y_categorical = to_categorical(y, num_classes=len(actions))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_categorical, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35120218",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "perm = np.random.permutation(len(X_train))\n",
    "X_train = X_train[perm]\n",
    "y_train = y_train[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2264757",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.squeeze(-1)\n",
    "X_test  = X_test.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51056d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1642, 30, 126, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5ff6911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1313, 30, 126)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "821d602e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights computed: {0: np.float64(2.0525), 1: np.float64(0.8552083333333333), 2: np.float64(1.642), 3: np.float64(1.3683333333333334), 4: np.float64(1.3241935483870968), 5: np.float64(0.9122222222222223), 6: np.float64(1.02625), 7: np.float64(0.9122222222222223), 8: np.float64(0.6729508196721311), 9: np.float64(1.1402777777777777), 10: np.float64(0.7894230769230769), 11: np.float64(1.3683333333333334), 12: np.float64(1.2828125), 13: np.float64(0.6957627118644067), 14: np.float64(0.6126865671641791), 15: np.float64(0.9773809523809524), 16: np.float64(0.9773809523809524), 17: np.float64(1.2828125), 18: np.float64(0.9546511627906977), 19: np.float64(1.001219512195122)}\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(f\"Class weights computed: {class_weight_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908e16ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755928187.151936  159375 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9001 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "/home/smayan/Desktop/AI-ML-DS/AI-and-ML-Course/.conda/lib/python3.11/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=(sequence_length, X.shape[2])))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "# model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(sequence_length, X.shape[2])))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(actions), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a796af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = f'logs/wsl_model_{timestamp}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "677d1713",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66e8fc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">261,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m261,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m164,352\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m660\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">431,284</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m431,284\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">430,772</span> (1.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m430,772\u001b[0m (1.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22367f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1313, 30, 126)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80cc6c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "MONITOR_METRIC = 'val_accuracy'\n",
    "MONITOR_MODE = 'max' \n",
    "\n",
    "log_dir = \"/home/smayan/Desktop/ASL/logs\"\n",
    "\n",
    "\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='best_asl_model.keras',\n",
    "    save_weights_only=False,        \n",
    "    monitor=MONITOR_METRIC,\n",
    "    mode=MONITOR_MODE,\n",
    "    save_best_only=True,            \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=MONITOR_METRIC,\n",
    "    patience=20,  \n",
    "    verbose=1,\n",
    "    mode=MONITOR_MODE,\n",
    "    restore_best_weights=True \n",
    ")\n",
    "\n",
    "reduce_lr_callback = ReduceLROnPlateau(\n",
    "    monitor=MONITOR_METRIC,\n",
    "    factor=0.2,\n",
    "    patience=10,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1,\n",
    "    mode=MONITOR_MODE\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "    model_checkpoint_callback, # <-- ADDED\n",
    "    early_stopping_callback,   # <-- MODIFIED\n",
    "    reduce_lr_callback       # <-- MODIFIED\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "263b751e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755928072.422998  144089 cuda_dnn.cc:529] Loaded cuDNN version 91100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m36/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0859 - loss: 2.9145\n",
      "Epoch 1: val_accuracy improved from -inf to 0.15502, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.0902 - loss: 2.8950 - val_accuracy: 0.1550 - val_loss: 2.8314 - learning_rate: 0.0010\n",
      "Epoch 2/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1769 - loss: 2.5645\n",
      "Epoch 2: val_accuracy improved from 0.15502 to 0.17021, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1779 - loss: 2.5618 - val_accuracy: 0.1702 - val_loss: 2.6007 - learning_rate: 0.0010\n",
      "Epoch 3/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2304 - loss: 2.3121\n",
      "Epoch 3: val_accuracy improved from 0.17021 to 0.27660, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2317 - loss: 2.3100 - val_accuracy: 0.2766 - val_loss: 2.3003 - learning_rate: 0.0010\n",
      "Epoch 4/150\n",
      "\u001b[1m38/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3155 - loss: 2.1322\n",
      "Epoch 4: val_accuracy improved from 0.27660 to 0.28875, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3150 - loss: 2.1291 - val_accuracy: 0.2888 - val_loss: 2.2627 - learning_rate: 0.0010\n",
      "Epoch 5/150\n",
      "\u001b[1m37/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3385 - loss: 1.9135\n",
      "Epoch 5: val_accuracy did not improve from 0.28875\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3387 - loss: 1.9155 - val_accuracy: 0.2827 - val_loss: 2.2335 - learning_rate: 0.0010\n",
      "Epoch 6/150\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3547 - loss: 1.8091\n",
      "Epoch 6: val_accuracy improved from 0.28875 to 0.34650, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3551 - loss: 1.8081 - val_accuracy: 0.3465 - val_loss: 1.9319 - learning_rate: 0.0010\n",
      "Epoch 7/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3708 - loss: 1.7407\n",
      "Epoch 7: val_accuracy improved from 0.34650 to 0.39818, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.3727 - loss: 1.7386 - val_accuracy: 0.3982 - val_loss: 1.7928 - learning_rate: 0.0010\n",
      "Epoch 8/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4354 - loss: 1.6476\n",
      "Epoch 8: val_accuracy did not improve from 0.39818\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4366 - loss: 1.6424 - val_accuracy: 0.3587 - val_loss: 1.8970 - learning_rate: 0.0010\n",
      "Epoch 9/150\n",
      "\u001b[1m37/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5110 - loss: 1.4920\n",
      "Epoch 9: val_accuracy improved from 0.39818 to 0.48024, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5082 - loss: 1.4910 - val_accuracy: 0.4802 - val_loss: 1.4951 - learning_rate: 0.0010\n",
      "Epoch 10/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4878 - loss: 1.4739\n",
      "Epoch 10: val_accuracy did not improve from 0.48024\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4878 - loss: 1.4732 - val_accuracy: 0.3252 - val_loss: 1.8458 - learning_rate: 0.0010\n",
      "Epoch 11/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4416 - loss: 1.5585\n",
      "Epoch 11: val_accuracy did not improve from 0.48024\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4416 - loss: 1.5577 - val_accuracy: 0.2249 - val_loss: 2.2990 - learning_rate: 0.0010\n",
      "Epoch 12/150\n",
      "\u001b[1m39/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4891 - loss: 1.4598\n",
      "Epoch 12: val_accuracy did not improve from 0.48024\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4905 - loss: 1.4548 - val_accuracy: 0.4316 - val_loss: 1.6094 - learning_rate: 0.0010\n",
      "Epoch 13/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5039 - loss: 1.3565\n",
      "Epoch 13: val_accuracy did not improve from 0.48024\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5051 - loss: 1.3551 - val_accuracy: 0.4590 - val_loss: 1.5254 - learning_rate: 0.0010\n",
      "Epoch 14/150\n",
      "\u001b[1m37/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6122 - loss: 1.1245\n",
      "Epoch 14: val_accuracy did not improve from 0.48024\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6084 - loss: 1.1310 - val_accuracy: 0.4650 - val_loss: 1.4792 - learning_rate: 0.0010\n",
      "Epoch 15/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5444 - loss: 1.3296\n",
      "Epoch 15: val_accuracy did not improve from 0.48024\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5438 - loss: 1.3292 - val_accuracy: 0.4073 - val_loss: 1.6008 - learning_rate: 0.0010\n",
      "Epoch 16/150\n",
      "\u001b[1m39/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5796 - loss: 1.2871\n",
      "Epoch 16: val_accuracy improved from 0.48024 to 0.53191, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5790 - loss: 1.2817 - val_accuracy: 0.5319 - val_loss: 1.3822 - learning_rate: 0.0010\n",
      "Epoch 17/150\n",
      "\u001b[1m39/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6020 - loss: 1.1212\n",
      "Epoch 17: val_accuracy improved from 0.53191 to 0.62918, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6026 - loss: 1.1206 - val_accuracy: 0.6292 - val_loss: 1.1223 - learning_rate: 0.0010\n",
      "Epoch 18/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6338 - loss: 1.0378\n",
      "Epoch 18: val_accuracy did not improve from 0.62918\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6339 - loss: 1.0383 - val_accuracy: 0.4407 - val_loss: 1.5502 - learning_rate: 0.0010\n",
      "Epoch 19/150\n",
      "\u001b[1m32/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6421 - loss: 1.0527\n",
      "Epoch 19: val_accuracy did not improve from 0.62918\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6382 - loss: 1.0600 - val_accuracy: 0.5441 - val_loss: 1.3072 - learning_rate: 0.0010\n",
      "Epoch 20/150\n",
      "\u001b[1m38/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6218 - loss: 1.0858\n",
      "Epoch 20: val_accuracy did not improve from 0.62918\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6251 - loss: 1.0748 - val_accuracy: 0.5805 - val_loss: 1.1714 - learning_rate: 0.0010\n",
      "Epoch 21/150\n",
      "\u001b[1m37/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6886 - loss: 0.9273\n",
      "Epoch 21: val_accuracy improved from 0.62918 to 0.63222, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6893 - loss: 0.9276 - val_accuracy: 0.6322 - val_loss: 1.0021 - learning_rate: 0.0010\n",
      "Epoch 22/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6982 - loss: 0.8802\n",
      "Epoch 22: val_accuracy did not improve from 0.63222\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6989 - loss: 0.8778 - val_accuracy: 0.5532 - val_loss: 1.3438 - learning_rate: 0.0010\n",
      "Epoch 23/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6610 - loss: 0.9974\n",
      "Epoch 23: val_accuracy did not improve from 0.63222\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6608 - loss: 0.9979 - val_accuracy: 0.5410 - val_loss: 1.3307 - learning_rate: 0.0010\n",
      "Epoch 24/150\n",
      "\u001b[1m36/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6805 - loss: 0.9129\n",
      "Epoch 24: val_accuracy did not improve from 0.63222\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6818 - loss: 0.9083 - val_accuracy: 0.4620 - val_loss: 1.4799 - learning_rate: 0.0010\n",
      "Epoch 25/150\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6730 - loss: 0.9895\n",
      "Epoch 25: val_accuracy improved from 0.63222 to 0.70821, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6733 - loss: 0.9882 - val_accuracy: 0.7082 - val_loss: 0.8655 - learning_rate: 0.0010\n",
      "Epoch 26/150\n",
      "\u001b[1m37/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7447 - loss: 0.7447\n",
      "Epoch 26: val_accuracy did not improve from 0.70821\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7450 - loss: 0.7423 - val_accuracy: 0.5988 - val_loss: 1.1308 - learning_rate: 0.0010\n",
      "Epoch 27/150\n",
      "\u001b[1m39/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7189 - loss: 0.8389\n",
      "Epoch 27: val_accuracy did not improve from 0.70821\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7194 - loss: 0.8373 - val_accuracy: 0.5228 - val_loss: 1.3817 - learning_rate: 0.0010\n",
      "Epoch 28/150\n",
      "\u001b[1m39/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7424 - loss: 0.7597\n",
      "Epoch 28: val_accuracy improved from 0.70821 to 0.73556, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7431 - loss: 0.7560 - val_accuracy: 0.7356 - val_loss: 0.7610 - learning_rate: 0.0010\n",
      "Epoch 29/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7881 - loss: 0.6215\n",
      "Epoch 29: val_accuracy improved from 0.73556 to 0.73860, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7885 - loss: 0.6219 - val_accuracy: 0.7386 - val_loss: 0.7346 - learning_rate: 0.0010\n",
      "Epoch 30/150\n",
      "\u001b[1m37/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7916 - loss: 0.6205\n",
      "Epoch 30: val_accuracy did not improve from 0.73860\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7920 - loss: 0.6225 - val_accuracy: 0.6292 - val_loss: 1.0931 - learning_rate: 0.0010\n",
      "Epoch 31/150\n",
      "\u001b[1m38/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7412 - loss: 0.7297\n",
      "Epoch 31: val_accuracy did not improve from 0.73860\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7396 - loss: 0.7348 - val_accuracy: 0.6657 - val_loss: 0.9470 - learning_rate: 0.0010\n",
      "Epoch 32/150\n",
      "\u001b[1m38/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7481 - loss: 0.7885\n",
      "Epoch 32: val_accuracy did not improve from 0.73860\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7500 - loss: 0.7829 - val_accuracy: 0.4650 - val_loss: 1.6191 - learning_rate: 0.0010\n",
      "Epoch 33/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7821 - loss: 0.6772\n",
      "Epoch 33: val_accuracy did not improve from 0.73860\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7824 - loss: 0.6763 - val_accuracy: 0.5866 - val_loss: 1.1642 - learning_rate: 0.0010\n",
      "Epoch 34/150\n",
      "\u001b[1m34/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7576 - loss: 0.7394\n",
      "Epoch 34: val_accuracy did not improve from 0.73860\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7578 - loss: 0.7374 - val_accuracy: 0.4894 - val_loss: 1.6533 - learning_rate: 0.0010\n",
      "Epoch 35/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7397 - loss: 0.7541\n",
      "Epoch 35: val_accuracy did not improve from 0.73860\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7399 - loss: 0.7543 - val_accuracy: 0.6109 - val_loss: 1.0834 - learning_rate: 0.0010\n",
      "Epoch 36/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8002 - loss: 0.6269\n",
      "Epoch 36: val_accuracy did not improve from 0.73860\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7996 - loss: 0.6285 - val_accuracy: 0.5319 - val_loss: 1.4249 - learning_rate: 0.0010\n",
      "Epoch 37/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7853 - loss: 0.7000\n",
      "Epoch 37: val_accuracy did not improve from 0.73860\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7858 - loss: 0.6975 - val_accuracy: 0.5380 - val_loss: 1.4797 - learning_rate: 0.0010\n",
      "Epoch 38/150\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7528 - loss: 0.7495\n",
      "Epoch 38: val_accuracy did not improve from 0.73860\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7531 - loss: 0.7489 - val_accuracy: 0.6140 - val_loss: 1.1732 - learning_rate: 0.0010\n",
      "Epoch 39/150\n",
      "\u001b[1m32/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7928 - loss: 0.6173\n",
      "Epoch 39: val_accuracy improved from 0.73860 to 0.78723, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7954 - loss: 0.6129 - val_accuracy: 0.7872 - val_loss: 0.6166 - learning_rate: 0.0010\n",
      "Epoch 40/150\n",
      "\u001b[1m39/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7814 - loss: 0.7108\n",
      "Epoch 40: val_accuracy did not improve from 0.78723\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7812 - loss: 0.7077 - val_accuracy: 0.5805 - val_loss: 1.0931 - learning_rate: 0.0010\n",
      "Epoch 41/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7252 - loss: 0.8739\n",
      "Epoch 41: val_accuracy did not improve from 0.78723\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7257 - loss: 0.8705 - val_accuracy: 0.5836 - val_loss: 1.1301 - learning_rate: 0.0010\n",
      "Epoch 42/150\n",
      "\u001b[1m38/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8196 - loss: 0.5497\n",
      "Epoch 42: val_accuracy did not improve from 0.78723\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8167 - loss: 0.5602 - val_accuracy: 0.6778 - val_loss: 0.8564 - learning_rate: 0.0010\n",
      "Epoch 43/150\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7526 - loss: 0.7215\n",
      "Epoch 43: val_accuracy did not improve from 0.78723\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7532 - loss: 0.7203 - val_accuracy: 0.6687 - val_loss: 0.9737 - learning_rate: 0.0010\n",
      "Epoch 44/150\n",
      "\u001b[1m35/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8263 - loss: 0.5873\n",
      "Epoch 44: val_accuracy did not improve from 0.78723\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8251 - loss: 0.5828 - val_accuracy: 0.7720 - val_loss: 0.6196 - learning_rate: 0.0010\n",
      "Epoch 45/150\n",
      "\u001b[1m33/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8339 - loss: 0.5117\n",
      "Epoch 45: val_accuracy improved from 0.78723 to 0.79635, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8336 - loss: 0.5117 - val_accuracy: 0.7964 - val_loss: 0.5903 - learning_rate: 0.0010\n",
      "Epoch 46/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8343 - loss: 0.4978\n",
      "Epoch 46: val_accuracy did not improve from 0.79635\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8342 - loss: 0.4981 - val_accuracy: 0.5593 - val_loss: 1.5074 - learning_rate: 0.0010\n",
      "Epoch 47/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8076 - loss: 0.5436\n",
      "Epoch 47: val_accuracy did not improve from 0.79635\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8078 - loss: 0.5428 - val_accuracy: 0.7933 - val_loss: 0.5529 - learning_rate: 0.0010\n",
      "Epoch 48/150\n",
      "\u001b[1m37/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8277 - loss: 0.5005\n",
      "Epoch 48: val_accuracy did not improve from 0.79635\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8289 - loss: 0.4996 - val_accuracy: 0.7477 - val_loss: 0.7175 - learning_rate: 0.0010\n",
      "Epoch 49/150\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8376 - loss: 0.4982\n",
      "Epoch 49: val_accuracy improved from 0.79635 to 0.81459, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8377 - loss: 0.4978 - val_accuracy: 0.8146 - val_loss: 0.5004 - learning_rate: 0.0010\n",
      "Epoch 50/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8115 - loss: 0.5781\n",
      "Epoch 50: val_accuracy did not improve from 0.81459\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8116 - loss: 0.5777 - val_accuracy: 0.6322 - val_loss: 1.0449 - learning_rate: 0.0010\n",
      "Epoch 51/150\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8402 - loss: 0.5333\n",
      "Epoch 51: val_accuracy did not improve from 0.81459\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8400 - loss: 0.5332 - val_accuracy: 0.7599 - val_loss: 0.6944 - learning_rate: 0.0010\n",
      "Epoch 52/150\n",
      "\u001b[1m38/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8466 - loss: 0.4450\n",
      "Epoch 52: val_accuracy did not improve from 0.81459\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8467 - loss: 0.4458 - val_accuracy: 0.2371 - val_loss: 3.7497 - learning_rate: 0.0010\n",
      "Epoch 53/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5753 - loss: 1.2950\n",
      "Epoch 53: val_accuracy did not improve from 0.81459\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5760 - loss: 1.2917 - val_accuracy: 0.2036 - val_loss: 3.5021 - learning_rate: 0.0010\n",
      "Epoch 54/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7094 - loss: 0.8086\n",
      "Epoch 54: val_accuracy did not improve from 0.81459\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7094 - loss: 0.8089 - val_accuracy: 0.4985 - val_loss: 1.5712 - learning_rate: 0.0010\n",
      "Epoch 55/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7283 - loss: 0.7048\n",
      "Epoch 55: val_accuracy did not improve from 0.81459\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7305 - loss: 0.7017 - val_accuracy: 0.7872 - val_loss: 0.6128 - learning_rate: 0.0010\n",
      "Epoch 56/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8066 - loss: 0.5506\n",
      "Epoch 56: val_accuracy did not improve from 0.81459\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8082 - loss: 0.5488 - val_accuracy: 0.6930 - val_loss: 0.7723 - learning_rate: 0.0010\n",
      "Epoch 57/150\n",
      "\u001b[1m39/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7506 - loss: 0.7381\n",
      "Epoch 57: val_accuracy did not improve from 0.81459\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7510 - loss: 0.7377 - val_accuracy: 0.5897 - val_loss: 1.3878 - learning_rate: 0.0010\n",
      "Epoch 58/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6761 - loss: 0.9852\n",
      "Epoch 58: val_accuracy did not improve from 0.81459\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6775 - loss: 0.9796 - val_accuracy: 0.7173 - val_loss: 0.8643 - learning_rate: 0.0010\n",
      "Epoch 59/150\n",
      "\u001b[1m35/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8246 - loss: 0.5229\n",
      "Epoch 59: val_accuracy did not improve from 0.81459\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8242 - loss: 0.5256 - val_accuracy: 0.5684 - val_loss: 1.6865 - learning_rate: 0.0010\n",
      "Epoch 60/150\n",
      "\u001b[1m32/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8426 - loss: 0.4617\n",
      "Epoch 60: val_accuracy did not improve from 0.81459\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8429 - loss: 0.4610 - val_accuracy: 0.7143 - val_loss: 0.8426 - learning_rate: 2.0000e-04\n",
      "Epoch 61/150\n",
      "\u001b[1m35/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8574 - loss: 0.4296\n",
      "Epoch 61: val_accuracy did not improve from 0.81459\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8600 - loss: 0.4264 - val_accuracy: 0.7994 - val_loss: 0.5782 - learning_rate: 2.0000e-04\n",
      "Epoch 62/150\n",
      "\u001b[1m33/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8372 - loss: 0.4493\n",
      "Epoch 62: val_accuracy did not improve from 0.81459\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8381 - loss: 0.4456 - val_accuracy: 0.7964 - val_loss: 0.5227 - learning_rate: 2.0000e-04\n",
      "Epoch 63/150\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8629 - loss: 0.3908\n",
      "Epoch 63: val_accuracy did not improve from 0.81459\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8633 - loss: 0.3904 - val_accuracy: 0.8085 - val_loss: 0.4515 - learning_rate: 2.0000e-04\n",
      "Epoch 64/150\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8776 - loss: 0.3830\n",
      "Epoch 64: val_accuracy did not improve from 0.81459\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8775 - loss: 0.3831 - val_accuracy: 0.7964 - val_loss: 0.5153 - learning_rate: 2.0000e-04\n",
      "Epoch 65/150\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8621 - loss: 0.3874\n",
      "Epoch 65: val_accuracy improved from 0.81459 to 0.83283, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8620 - loss: 0.3875 - val_accuracy: 0.8328 - val_loss: 0.4239 - learning_rate: 2.0000e-04\n",
      "Epoch 66/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8896 - loss: 0.3548\n",
      "Epoch 66: val_accuracy did not improve from 0.83283\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8892 - loss: 0.3548 - val_accuracy: 0.8146 - val_loss: 0.4556 - learning_rate: 2.0000e-04\n",
      "Epoch 67/150\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8950 - loss: 0.3457\n",
      "Epoch 67: val_accuracy did not improve from 0.83283\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8946 - loss: 0.3466 - val_accuracy: 0.8116 - val_loss: 0.5053 - learning_rate: 2.0000e-04\n",
      "Epoch 68/150\n",
      "\u001b[1m33/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8977 - loss: 0.3712\n",
      "Epoch 68: val_accuracy did not improve from 0.83283\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8952 - loss: 0.3684 - val_accuracy: 0.8146 - val_loss: 0.4398 - learning_rate: 2.0000e-04\n",
      "Epoch 69/150\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9136 - loss: 0.2938\n",
      "Epoch 69: val_accuracy improved from 0.83283 to 0.84195, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9132 - loss: 0.2949 - val_accuracy: 0.8419 - val_loss: 0.3933 - learning_rate: 2.0000e-04\n",
      "Epoch 70/150\n",
      "\u001b[1m34/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8756 - loss: 0.3618\n",
      "Epoch 70: val_accuracy did not improve from 0.84195\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8749 - loss: 0.3631 - val_accuracy: 0.8298 - val_loss: 0.4211 - learning_rate: 2.0000e-04\n",
      "Epoch 71/150\n",
      "\u001b[1m34/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8943 - loss: 0.3315\n",
      "Epoch 71: val_accuracy did not improve from 0.84195\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8938 - loss: 0.3317 - val_accuracy: 0.8328 - val_loss: 0.3955 - learning_rate: 2.0000e-04\n",
      "Epoch 72/150\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8896 - loss: 0.3214\n",
      "Epoch 72: val_accuracy did not improve from 0.84195\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8895 - loss: 0.3221 - val_accuracy: 0.8267 - val_loss: 0.4062 - learning_rate: 2.0000e-04\n",
      "Epoch 73/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8844 - loss: 0.3510\n",
      "Epoch 73: val_accuracy did not improve from 0.84195\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8844 - loss: 0.3506 - val_accuracy: 0.8267 - val_loss: 0.4082 - learning_rate: 2.0000e-04\n",
      "Epoch 74/150\n",
      "\u001b[1m35/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8856 - loss: 0.3332\n",
      "Epoch 74: val_accuracy improved from 0.84195 to 0.84498, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8859 - loss: 0.3341 - val_accuracy: 0.8450 - val_loss: 0.3952 - learning_rate: 2.0000e-04\n",
      "Epoch 75/150\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9050 - loss: 0.3251\n",
      "Epoch 75: val_accuracy did not improve from 0.84498\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9048 - loss: 0.3250 - val_accuracy: 0.8359 - val_loss: 0.4135 - learning_rate: 2.0000e-04\n",
      "Epoch 76/150\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8878 - loss: 0.3316\n",
      "Epoch 76: val_accuracy did not improve from 0.84498\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8878 - loss: 0.3316 - val_accuracy: 0.8450 - val_loss: 0.4159 - learning_rate: 2.0000e-04\n",
      "Epoch 77/150\n",
      "\u001b[1m33/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8968 - loss: 0.3187\n",
      "Epoch 77: val_accuracy did not improve from 0.84498\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8975 - loss: 0.3173 - val_accuracy: 0.8389 - val_loss: 0.4007 - learning_rate: 2.0000e-04\n",
      "Epoch 78/150\n",
      "\u001b[1m32/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9029 - loss: 0.2920\n",
      "Epoch 78: val_accuracy did not improve from 0.84498\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9012 - loss: 0.2929 - val_accuracy: 0.8419 - val_loss: 0.3979 - learning_rate: 2.0000e-04\n",
      "Epoch 79/150\n",
      "\u001b[1m32/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8734 - loss: 0.3344\n",
      "Epoch 79: val_accuracy improved from 0.84498 to 0.84802, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8787 - loss: 0.3300 - val_accuracy: 0.8480 - val_loss: 0.3919 - learning_rate: 2.0000e-04\n",
      "Epoch 80/150\n",
      "\u001b[1m32/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8926 - loss: 0.2778\n",
      "Epoch 80: val_accuracy did not improve from 0.84802\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8896 - loss: 0.2898 - val_accuracy: 0.8328 - val_loss: 0.4103 - learning_rate: 2.0000e-04\n",
      "Epoch 81/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8902 - loss: 0.3211\n",
      "Epoch 81: val_accuracy did not improve from 0.84802\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8903 - loss: 0.3222 - val_accuracy: 0.8359 - val_loss: 0.4065 - learning_rate: 2.0000e-04\n",
      "Epoch 82/150\n",
      "\u001b[1m34/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8704 - loss: 0.3614\n",
      "Epoch 82: val_accuracy did not improve from 0.84802\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8733 - loss: 0.3554 - val_accuracy: 0.8450 - val_loss: 0.4120 - learning_rate: 2.0000e-04\n",
      "Epoch 83/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8896 - loss: 0.3482\n",
      "Epoch 83: val_accuracy did not improve from 0.84802\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8897 - loss: 0.3473 - val_accuracy: 0.8237 - val_loss: 0.4577 - learning_rate: 2.0000e-04\n",
      "Epoch 84/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8904 - loss: 0.3182\n",
      "Epoch 84: val_accuracy did not improve from 0.84802\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8905 - loss: 0.3183 - val_accuracy: 0.8207 - val_loss: 0.4491 - learning_rate: 2.0000e-04\n",
      "Epoch 85/150\n",
      "\u001b[1m33/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9183 - loss: 0.2908\n",
      "Epoch 85: val_accuracy did not improve from 0.84802\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9144 - loss: 0.2945 - val_accuracy: 0.8389 - val_loss: 0.3994 - learning_rate: 2.0000e-04\n",
      "Epoch 86/150\n",
      "\u001b[1m34/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9102 - loss: 0.2821\n",
      "Epoch 86: val_accuracy did not improve from 0.84802\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9081 - loss: 0.2871 - val_accuracy: 0.8207 - val_loss: 0.4070 - learning_rate: 2.0000e-04\n",
      "Epoch 87/150\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8929 - loss: 0.3195\n",
      "Epoch 87: val_accuracy improved from 0.84802 to 0.85106, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8930 - loss: 0.3191 - val_accuracy: 0.8511 - val_loss: 0.3912 - learning_rate: 2.0000e-04\n",
      "Epoch 88/150\n",
      "\u001b[1m39/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9125 - loss: 0.2840\n",
      "Epoch 88: val_accuracy did not improve from 0.85106\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9118 - loss: 0.2851 - val_accuracy: 0.8450 - val_loss: 0.3885 - learning_rate: 2.0000e-04\n",
      "Epoch 89/150\n",
      "\u001b[1m34/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9091 - loss: 0.3287\n",
      "Epoch 89: val_accuracy did not improve from 0.85106\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9109 - loss: 0.3190 - val_accuracy: 0.8480 - val_loss: 0.4001 - learning_rate: 2.0000e-04\n",
      "Epoch 90/150\n",
      "\u001b[1m32/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9049 - loss: 0.2879\n",
      "Epoch 90: val_accuracy improved from 0.85106 to 0.85410, saving model to best_asl_model.keras\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9045 - loss: 0.2914 - val_accuracy: 0.8541 - val_loss: 0.3939 - learning_rate: 2.0000e-04\n",
      "Epoch 91/150\n",
      "\u001b[1m33/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9055 - loss: 0.2706\n",
      "Epoch 91: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9041 - loss: 0.2792 - val_accuracy: 0.8389 - val_loss: 0.3942 - learning_rate: 2.0000e-04\n",
      "Epoch 92/150\n",
      "\u001b[1m33/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9114 - loss: 0.2670\n",
      "Epoch 92: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9099 - loss: 0.2694 - val_accuracy: 0.8389 - val_loss: 0.4085 - learning_rate: 2.0000e-04\n",
      "Epoch 93/150\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9135 - loss: 0.2885\n",
      "Epoch 93: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9135 - loss: 0.2882 - val_accuracy: 0.8480 - val_loss: 0.3951 - learning_rate: 2.0000e-04\n",
      "Epoch 94/150\n",
      "\u001b[1m32/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9094 - loss: 0.2692\n",
      "Epoch 94: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9062 - loss: 0.2752 - val_accuracy: 0.8480 - val_loss: 0.3981 - learning_rate: 2.0000e-04\n",
      "Epoch 95/150\n",
      "\u001b[1m36/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8995 - loss: 0.3134\n",
      "Epoch 95: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8993 - loss: 0.3128 - val_accuracy: 0.8450 - val_loss: 0.4014 - learning_rate: 2.0000e-04\n",
      "Epoch 96/150\n",
      "\u001b[1m33/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9010 - loss: 0.2834\n",
      "Epoch 96: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9023 - loss: 0.2814 - val_accuracy: 0.8511 - val_loss: 0.4098 - learning_rate: 2.0000e-04\n",
      "Epoch 97/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8991 - loss: 0.2986\n",
      "Epoch 97: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8988 - loss: 0.2993 - val_accuracy: 0.8298 - val_loss: 0.4847 - learning_rate: 2.0000e-04\n",
      "Epoch 98/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8683 - loss: 0.3879\n",
      "Epoch 98: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8677 - loss: 0.3889 - val_accuracy: 0.6960 - val_loss: 0.9881 - learning_rate: 2.0000e-04\n",
      "Epoch 99/150\n",
      "\u001b[1m34/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8906 - loss: 0.3269\n",
      "Epoch 99: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8922 - loss: 0.3229 - val_accuracy: 0.8207 - val_loss: 0.4370 - learning_rate: 2.0000e-04\n",
      "Epoch 100/150\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9128 - loss: 0.2685\n",
      "Epoch 100: val_accuracy did not improve from 0.85410\n",
      "\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9127 - loss: 0.2690 - val_accuracy: 0.8389 - val_loss: 0.3865 - learning_rate: 2.0000e-04\n",
      "Epoch 101/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9240 - loss: 0.2480\n",
      "Epoch 101: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9238 - loss: 0.2491 - val_accuracy: 0.8328 - val_loss: 0.3854 - learning_rate: 4.0000e-05\n",
      "Epoch 102/150\n",
      "\u001b[1m32/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9078 - loss: 0.2956\n",
      "Epoch 102: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9080 - loss: 0.2927 - val_accuracy: 0.8359 - val_loss: 0.3815 - learning_rate: 4.0000e-05\n",
      "Epoch 103/150\n",
      "\u001b[1m33/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9057 - loss: 0.2872\n",
      "Epoch 103: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9056 - loss: 0.2880 - val_accuracy: 0.8480 - val_loss: 0.3805 - learning_rate: 4.0000e-05\n",
      "Epoch 104/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9105 - loss: 0.2690\n",
      "Epoch 104: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9102 - loss: 0.2695 - val_accuracy: 0.8450 - val_loss: 0.3949 - learning_rate: 4.0000e-05\n",
      "Epoch 105/150\n",
      "\u001b[1m32/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9137 - loss: 0.2783\n",
      "Epoch 105: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9140 - loss: 0.2758 - val_accuracy: 0.8419 - val_loss: 0.3861 - learning_rate: 4.0000e-05\n",
      "Epoch 106/150\n",
      "\u001b[1m38/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9183 - loss: 0.2576\n",
      "Epoch 106: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9168 - loss: 0.2605 - val_accuracy: 0.8389 - val_loss: 0.3874 - learning_rate: 4.0000e-05\n",
      "Epoch 107/150\n",
      "\u001b[1m36/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9176 - loss: 0.2883\n",
      "Epoch 107: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9169 - loss: 0.2847 - val_accuracy: 0.8450 - val_loss: 0.3848 - learning_rate: 4.0000e-05\n",
      "Epoch 108/150\n",
      "\u001b[1m33/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9120 - loss: 0.2752\n",
      "Epoch 108: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9099 - loss: 0.2757 - val_accuracy: 0.8419 - val_loss: 0.3959 - learning_rate: 4.0000e-05\n",
      "Epoch 109/150\n",
      "\u001b[1m40/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9063 - loss: 0.2923\n",
      "Epoch 109: val_accuracy did not improve from 0.85410\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9059 - loss: 0.2925 - val_accuracy: 0.8450 - val_loss: 0.3915 - learning_rate: 4.0000e-05\n",
      "Epoch 110/150\n",
      "\u001b[1m41/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9003 - loss: 0.2983\n",
      "Epoch 110: val_accuracy did not improve from 0.85410\n",
      "\n",
      "Epoch 110: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9004 - loss: 0.2973 - val_accuracy: 0.8419 - val_loss: 0.3898 - learning_rate: 4.0000e-05\n",
      "Epoch 110: early stopping\n",
      "Restoring model weights from the end of the best epoch: 90.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=150,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks,\n",
    "    class_weight=class_weight_dict,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44a5c55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.3939\n",
      "Test Accuracy: 85.41%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nTest Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2a1f0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved as wsl_model_20250823-111750.h5\n"
     ]
    }
   ],
   "source": [
    "model.save(f'augment_main_less_actions_main_wsl_model_{timestamp}.h5')\n",
    "print(f\"\\nModel saved as wsl_model_{timestamp}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee576bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1755928194.016961  159375 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1755928194.056495  159787 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 570.172.08), renderer: NVIDIA GeForce RTX 4070 SUPER/PCIe/SSE2\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1755928194.103512  159763 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755928194.120772  159766 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755928194.122894  159770 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755928194.123650  159779 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755928194.123761  159781 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755928194.130924  159776 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755928194.131118  159780 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "W0000 00:00:1755928194.135514  159762 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755928194.136118  159767 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1755928195.454071  159648 cuda_dnn.cc:529] Loaded cuDNN version 91100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 18\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 5\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 10\n",
      "res shape: (20,)\n",
      "argmax: 10\n",
      "res shape: (20,)\n",
      "argmax: 10\n",
      "res shape: (20,)\n",
      "argmax: 10\n",
      "res shape: (20,)\n",
      "argmax: 10\n",
      "res shape: (20,)\n",
      "argmax: 10\n",
      "res shape: (20,)\n",
      "argmax: 10\n",
      "res shape: (20,)\n",
      "argmax: 10\n",
      "res shape: (20,)\n",
      "argmax: 10\n",
      "res shape: (20,)\n",
      "argmax: 10\n",
      "res shape: (20,)\n",
      "argmax: 10\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 17\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 1\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 15\n",
      "res shape: (20,)\n",
      "argmax: 15\n",
      "res shape: (20,)\n",
      "argmax: 15\n",
      "res shape: (20,)\n",
      "argmax: 15\n",
      "res shape: (20,)\n",
      "argmax: 15\n",
      "res shape: (20,)\n",
      "argmax: 15\n",
      "res shape: (20,)\n",
      "argmax: 15\n",
      "res shape: (20,)\n",
      "argmax: 15\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n",
      "res shape: (20,)\n",
      "argmax: 14\n"
     ]
    }
   ],
   "source": [
    "# Load trained model and label map\n",
    "model = tf.keras.models.load_model('/home/smayan/Desktop/ASL/no face/augment_main_less_actions_main_wsl_model_20250823-111459.h5')\n",
    "# label_map = np.load('/home/smayan/Desktop/ASL/no face/label_map.npy', allow_pickle=True).item()\n",
    "actions = list(label_map.keys())\n",
    "\n",
    "# Variables for prediction\n",
    "sequence = []\n",
    "sequence_length = 30\n",
    "threshold = 0.7\n",
    "\n",
    "# Start webcam / video\n",
    "cap = cv.VideoCapture('/home/smayan/Desktop/ASL/ssvid.net--breakfast-in-ASL_1080pFHR.mp4')\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize for consistency\n",
    "        frame = cv.resize(frame, (640, 480))\n",
    "\n",
    "        # Detection\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        # Extract keypoints (same as training)\n",
    "        keypoints = extract_keypoints(results)\n",
    "\n",
    "        # Append to sequence\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-sequence_length:]\n",
    "\n",
    "        if len(sequence) == sequence_length:\n",
    "            input_seq = np.expand_dims(sequence, axis=0)   # shape (1, 30, 1530)\n",
    "\n",
    "            # Predict\n",
    "            res = model.predict(input_seq, verbose=0)[0]\n",
    "            print(\"res shape:\", res.shape)\n",
    "            print(\"argmax:\", np.argmax(res))\n",
    "\n",
    "            predicted_action = actions[np.argmax(res)]\n",
    "            confidence = np.max(res)\n",
    "\n",
    "            # Show prediction if above threshold\n",
    "            if confidence > threshold:\n",
    "                cv.putText(image, f'{predicted_action}: {confidence:.2f}',\n",
    "                           (10, 50), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            # Show probabilities\n",
    "            for i, (action, prob) in enumerate(zip(actions, res)):\n",
    "                y_pos = 100 + i * 30\n",
    "                cv.rectangle(image, (10, y_pos), (int(prob * 300) + 10, y_pos + 25), (0, 255, 0), -1)\n",
    "                cv.putText(image, f'{action}: {prob:.2f}', (15, y_pos + 18),\n",
    "                           cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "        # Show output\n",
    "        cv.imshow('ASL Inference', image)\n",
    "\n",
    "        # Quit\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a54f5052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: (None, 20)\n",
      "Number of actions: 20\n",
      "Actions: ['hello', 'student', 'i', 'bye', 'goodbye', 'college', 'wrong', 'how', 'work', 'your', 'want', 'nice', 'to', 'meet', 'doctor', 'time', 'age', 'breakfast', 'sorry', 'love']\n"
     ]
    }
   ],
   "source": [
    "print(\"Model output shape:\", model.output_shape)  # e.g. (None, 10)\n",
    "print(\"Number of actions:\", len(actions))\n",
    "print(\"Actions:\", actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad8bc39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

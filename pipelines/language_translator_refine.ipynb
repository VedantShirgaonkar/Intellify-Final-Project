{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86df5853",
   "metadata": {},
   "source": [
    "\n",
    "# Best Methods — Stages 1–3 (Gloss → Fluent English → On‑Demand Refine → Translate)\n",
    "\n",
    "This notebook implements the **Best** (highest‑quality, cloud‑powered) methods for the first three stages of your pipeline:\n",
    "\n",
    "1. **Stage 1 — Gloss → Fluent English (one‑shot LLM)**  \n",
    "   The LLM converts gloss tokens to natural, grammatical English in a single step (includes auto‑refine).\n",
    "\n",
    "2. **Stage 2 — On‑Demand Refine (button action)**  \n",
    "   A stronger LLM editor pass that returns a **structured JSON** showing what changed and why.\n",
    "\n",
    "3. **Stage 3 — Translation (English → target language)**  \n",
    "   A high‑quality LLM translation with tone/style hints and entity preservation.\n",
    "\n",
    "> **Prereqs (before running):**\n",
    "> - `pip install openai python-dotenv` (or set `OPENAI_API_KEY` in your environment).\n",
    "> - Your CV stage should output **gloss tokens** (list of strings). You can plug them into the helper below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06d87dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# If needed, uncomment to install packages in your environment:\n",
    "!pip install --quiet openai python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a139c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Imports & API key setup ----\n",
    "import os\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "# OpenAI SDK (Responses API)\n",
    "from openai import OpenAI\n",
    "\n",
    "# Optional: load .env if you keep your key there\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Expect OPENAI_API_KEY to be set in environment\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"Please set OPENAI_API_KEY (e.g., in your shell or a .env file).\"\n",
    "\n",
    "client = OpenAI()  # picks up key from env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2946c852",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Small pretty-printer for JSON output (for Stage 2)\n",
    "def pretty_json(obj: Any) -> str:\n",
    "    return json.dumps(obj, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ea6be2",
   "metadata": {},
   "source": [
    "\n",
    "## Stage 1 — Gloss → Fluent English (LLM; one shot)\n",
    "\n",
    "**What it does**  \n",
    "- Accepts a list of **gloss tokens** (e.g., `[\"YESTERDAY\", \"STORE\", \"I\", \"GO\"]`).  \n",
    "- Produces a **natural English sentence** with correct word order, articles, tense, punctuation, and capitalization.  \n",
    "- Preserves **names/numbers/fingerspelled tokens** when present (tip: you can tag them upstream).\n",
    "\n",
    "**Why this is “Best”**  \n",
    "- A high‑quality LLM handles contextual reordering and inserts missing function words, which rule‑based methods often miss.\n",
    "\n",
    "**Latency tip**  \n",
    "- Keep **temperature low** (e.g., `0.2`) for deterministic, stable phrasing in real time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a8ac533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def gloss_to_english_llm(\n",
    "    gloss_tokens: List[str],\n",
    "    context_hint: Optional[str] = None,\n",
    "    temperature: float = 0.2,\n",
    "    model: str = \"gpt-4o-mini\"\n",
    ") -> str:\n",
    "    \"\"\"Convert a list of gloss tokens into a fluent English sentence using an LLM.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gloss_tokens : list of str\n",
    "        Tokens from the CV recognizer (e.g., WSASL/ASL/ISL glosses).\n",
    "    context_hint : str, optional\n",
    "        Optional short context (topic/domain) to help resolve ambiguous glosses.\n",
    "    temperature : float\n",
    "        Lower values → more deterministic output.\n",
    "    model : str\n",
    "        OpenAI model to use.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A single, natural English sentence ending with proper punctuation.\n",
    "    \"\"\"\n",
    "    # 1) Prepare the instruction; we specify constraints to preserve semantics.\n",
    "    system = (\n",
    "        \"You are a precise sign-language translator. \"\n",
    "        \"Convert gloss tokens to a natural English sentence with correct grammar, \"\n",
    "        \"articles, tense, and punctuation. Do not add new facts beyond what is implied \"\n",
    "        \"by the glosses. Preserve named entities and numbers exactly. Output only the sentence.\"\n",
    "    )\n",
    "\n",
    "    # 2) Provide a couple of tiny few-shot examples to stabilize style.\n",
    "    examples = [\n",
    "        {\n",
    "            \"gloss\": [\"YESTERDAY\", \"STORE\", \"I\", \"GO\"],\n",
    "            \"english\": \"I went to the store yesterday.\"\n",
    "        },\n",
    "        {\n",
    "            \"gloss\": [\"TODAY\", \"SCHOOL\", \"WE\", \"MEET\", \"AFTERNOON\"],\n",
    "            \"english\": \"We will meet at school this afternoon.\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # 3) Compose user content with the current tokens and optional context.\n",
    "    user_lines = []\n",
    "    if context_hint:\n",
    "        user_lines.append(f\"Context: {context_hint}\")\n",
    "    user_lines.append(\"Gloss tokens: \" + \" \".join(gloss_tokens))\n",
    "    user_lines.append(\"Return a single complete English sentence.\")\n",
    "    user_prompt = \"\\n\".join(user_lines)\n",
    "\n",
    "    # 4) Build an input string combining instruction + few-shots + current request.\n",
    "    #    Using the Responses API with `input` keeps things simple.\n",
    "    few_shot_text = \"\\n\\n\".join([\n",
    "        f\"Example gloss: {' '.join(ex['gloss'])}\\nExample English: {ex['english']}\"\n",
    "        for ex in examples\n",
    "    ])\n",
    "\n",
    "    full_input = (\n",
    "        f\"System: {system}\\n\\n\"\n",
    "        f\"{few_shot_text}\\n\\n\"\n",
    "        f\"Now, translate the following into one fluent English sentence.\\n\"\n",
    "        f\"{user_prompt}\"\n",
    "    )\n",
    "\n",
    "    # 5) Call the model. Keep temperature low for consistency.\n",
    "    resp = client.responses.create(\n",
    "        model=model,\n",
    "        input=full_input,\n",
    "        temperature=temperature\n",
    "    )\n",
    "\n",
    "    # 6) Extract the plain text. The SDK exposes output_text for convenience.\n",
    "    sentence = resp.output_text.strip()\n",
    "\n",
    "    # 7) Ensure final punctuation.\n",
    "    if not sentence.endswith(('.', '!', '?')):\n",
    "        sentence += \".\"\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6465f4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went to the store yesterday.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Demo (replace with your CV output) ---\n",
    "demo_gloss = [\"YESTERDAY\", \"STORE\", \"I\", \"GO\"]\n",
    "english_sentence = gloss_to_english_llm(demo_gloss, context_hint=\"Daily activities\")\n",
    "print(english_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed47384",
   "metadata": {},
   "source": [
    "\n",
    "## Stage 2 — On‑Demand Refine (LLM editor with JSON diff)\n",
    "\n",
    "**What it does**  \n",
    "- Given a sentence (typically the Stage‑1 output), returns a **refined** version and a **list of changes**.  \n",
    "- Uses **structured JSON** so your UI can show a “what changed” diff.\n",
    "\n",
    "**Why this is “Best”**  \n",
    "- Provides higher fluency and user‑trust via transparent edits.  \n",
    "- We ask the model to **return JSON only** and use `response_format={\"type\": \"json_object\"}` to ensure valid JSON.\n",
    "\n",
    "**Schema we expect**  \n",
    "```json\n",
    "{\n",
    "  \"clean_text\": \"string\",\n",
    "  \"changes\": [\n",
    "    {\"type\": \"grammar|style|punctuation\", \"before\": \"str\", \"after\": \"str\", \"explanation\": \"str\"}\n",
    "  ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a16df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def refine_sentence_with_changes(\n",
    "    sentence: str,\n",
    "    temperature: float = 0.2,\n",
    "    model: str = \"gpt-4o-mini\"\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Refine a sentence and return a structured JSON with the clean text and changes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict with keys:\n",
    "      - clean_text: str\n",
    "      - changes: list[dict] with keys {type, before, after, explanation}\n",
    "    \"\"\"\n",
    "    system = (\n",
    "        \"You are a careful, minimal editor. Improve grammar, clarity, and punctuation \"\n",
    "        \"without changing the meaning. Preserve names and numbers exactly. \"\n",
    "        \"Return only JSON; do not include any extra commentary.\"\n",
    "    )\n",
    "\n",
    "    # We instruct the model to follow our JSON shape and enforce JSON output.\n",
    "    prompt = (\n",
    "        \"Edit the following sentence. Return JSON with keys: \"\n",
    "        \"'clean_text' (string) and 'changes' (array of objects with keys \"\n",
    "        \"'type', 'before', 'after', 'explanation').\\n\\n\"\n",
    "        f\"Sentence: {sentence}\"\n",
    "    )\n",
    "\n",
    "    resp = client.responses.create(\n",
    "        model=model,\n",
    "        input=f\"System: {system}\\n\\nUser: {prompt}\",\n",
    "        temperature=temperature,\n",
    "        #response_format={ \"type\": \"json_object\" }  # ensures valid JSON\n",
    "    )\n",
    "\n",
    "    # Parse the JSON from the text output.\n",
    "    data = json.loads(resp.output_text)\n",
    "\n",
    "    # Minimal sanity checks\n",
    "    data.setdefault(\"clean_text\", sentence)\n",
    "    data.setdefault(\"changes\", [])\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80f82507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"clean_text\": \"I went to the store yesterday.\",\n",
      "  \"changes\": []\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Demo for Stage 2 ---\n",
    "to_refine = english_sentence  # from Stage 1\n",
    "refined = refine_sentence_with_changes(to_refine)\n",
    "print(pretty_json(refined))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dc0827",
   "metadata": {},
   "source": [
    "\n",
    "## Stage 3 — Translation (English → target language)\n",
    "\n",
    "**What it does**  \n",
    "- Translates the (optionally refined) English sentence into a **target language** chosen by the user.  \n",
    "- Preserves named entities and numbers; supports tone (`formal` / `informal`) and optional locale hints.\n",
    "\n",
    "**Why this is “Best”**  \n",
    "- High‑quality LLM translation is robust to varied syntax and domain contexts.\n",
    "\n",
    "**Usage**  \n",
    "- Call `translate_text_llm(text, target_lang=\"hi\", tone=\"formal\")`  \n",
    "- `target_lang` can be a **language name** (`\"Hindi\"`) or a **BCP‑47/ISO code** (`\"hi\"`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab6378af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def translate_text_llm(\n",
    "    text: str,\n",
    "    target_lang: str,\n",
    "    tone: str = \"neutral\",\n",
    "    locale_hint: Optional[str] = None,\n",
    "    temperature: float = 0.2,\n",
    "    model: str = \"gpt-4o-mini\"\n",
    ") -> str:\n",
    "    \"\"\"Translate English text to a target language using an LLM.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        The English source sentence.\n",
    "    target_lang : str\n",
    "        Language name or code (e.g., 'Hindi' or 'hi').\n",
    "    tone : str\n",
    "        'formal', 'informal', or 'neutral' (hint only).\n",
    "    locale_hint : str, optional\n",
    "        Optional locale/region style (e.g., 'IN' for India).\n",
    "    temperature : float\n",
    "        Keep low for consistent, literal translations when desired.\n",
    "    model : str\n",
    "        OpenAI model to use.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The translated sentence only (no extra commentary).\n",
    "    \"\"\"\n",
    "    system = (\n",
    "        \"You are a professional translator. Translate the user's text to the requested \"\n",
    "        \"target language. Preserve names and numbers exactly. Do not add explanations. \"\n",
    "        \"Return only the translated sentence.\"\n",
    "    )\n",
    "\n",
    "    hints = [\n",
    "        f\"Target language: {target_lang}\",\n",
    "        f\"Tone: {tone}\"\n",
    "    ]\n",
    "    if locale_hint:\n",
    "        hints.append(f\"Locale hint: {locale_hint}\")\n",
    "    hint_text = \" | \".join(hints)\n",
    "\n",
    "    prompt = f\"{hint_text}\\n\\nText:\\n{text}\"\n",
    "\n",
    "    resp = client.responses.create(\n",
    "        model=model,\n",
    "        input=f\"System: {system}\\n\\nUser: {prompt}\",\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return resp.output_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f069fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN  : I went to the store yesterday.\n",
      "HI  : मैं कल दुकान गया था।\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Demo for Stage 3 ---\n",
    "final_english = refined.get(\"clean_text\", english_sentence)\n",
    "translated_hi = translate_text_llm(final_english, target_lang=\"Hindi\", tone=\"formal\", locale_hint=\"IN\")\n",
    "print(\"EN  :\", final_english)\n",
    "print(\"HI  :\", translated_hi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c1ebf4",
   "metadata": {},
   "source": [
    "\n",
    "### (Optional) Convenience wrapper — run Stages 1→2→3\n",
    "\n",
    "Use `run_best_pipeline` when you want to go end‑to‑end for a single sentence.  \n",
    "For **real‑time**, you should call Stage 1 for each finalized chunk, and then trigger Stage 2 only when the user taps **Refine**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3747561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class BestPipelineResult:\n",
    "    english: str\n",
    "    refined: Dict[str, Any]\n",
    "    translated: str\n",
    "\n",
    "def run_best_pipeline(\n",
    "    gloss_tokens: List[str],\n",
    "    target_lang: str,\n",
    "    tone: str = \"neutral\",\n",
    "    locale_hint: Optional[str] = None,\n",
    "    do_refine: bool = True\n",
    ") -> BestPipelineResult:\n",
    "    \"\"\"Run Stages 1→2→3 for a single sentence/chunk.\"\"\"\n",
    "    # Stage 1\n",
    "    english = gloss_to_english_llm(gloss_tokens)\n",
    "\n",
    "    # Stage 2 (optional button in the UI)\n",
    "    refined = refine_sentence_with_changes(english) if do_refine else {\"clean_text\": english, \"changes\": []}\n",
    "\n",
    "    # Stage 3\n",
    "    translated = translate_text_llm(refined[\"clean_text\"], target_lang=target_lang, tone=tone, locale_hint=locale_hint)\n",
    "\n",
    "    return BestPipelineResult(english=english, refined=refined, translated=translated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a58ed88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage 1 (English): We will meet at school this afternoon.\n",
      "\n",
      "Stage 2 (Refined JSON):\n",
      " {\n",
      "  \"clean_text\": \"We will meet at school this afternoon.\",\n",
      "  \"changes\": []\n",
      "}\n",
      "\n",
      "Stage 3 (Translated): हम इस दोपहर स्कूल में मिलेंगे।\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result = run_best_pipeline([\"TODAY\", \"SCHOOL\", \"WE\", \"MEET\", \"AFTERNOON\"], target_lang=\"Hindi\", tone=\"formal\", locale_hint=\"IN\")\n",
    "print(\"Stage 1 (English):\", result.english)\n",
    "print(\"\\nStage 2 (Refined JSON):\\n\", pretty_json(result.refined))\n",
    "print(\"\\nStage 3 (Translated):\", result.translated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf34926",
   "metadata": {},
   "source": [
    "\n",
    "### Notes & Tips\n",
    "\n",
    "- **Boundaries:** Call Stage 1 only on **finalized chunks** (e.g., clause/sentence boundaries) from your CV pipeline for stable output.\n",
    "- **Caching:** Add a dict cache keyed by the sentence string to avoid repeated LLM calls during demos.\n",
    "- **Tone Controls:** For translation, you can set `tone=\"formal\"` or `\"informal\"` based on user preference.\n",
    "- **Entity Protection:** Upstream, you can wrap entities like `«Vedant»` so the model keeps casing; then strip markers after translation.\n",
    "- **Costs & Latency:** Keep `temperature=0.2` and sentences short; batch only when safe. Consider streaming for UI responsiveness.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

import os

import json

from dataclasses import dataclass

from typing import List, Dict, Any, Optional

from openai import OpenAI

 

try:

    from dotenv import load_dotenv

    load_dotenv()

except Exception:

    pass

 

assert os.getenv("OPENAI_API_KEY"), "Please set OPENAI_API_KEY (e.g., in your shell or a .env file)."

client = OpenAI() 




def gloss_to_english_llm(

    gloss_tokens: List[str],

    context_hint: Optional[str] = None,

    temperature: float = 0.2,

    model: str = "gpt-4o-mini"

) -> str:

    """Convert a list of gloss tokens into a fluent English sentence using an LLM.

 

    Parameters

    ----------

    gloss_tokens : list of str

        Tokens from the CV recognizer (e.g., WSASL/ASL/ISL glosses).

    context_hint : str, optional

        Optional short context (topic/domain) to help resolve ambiguous glosses.

    temperature : float

        Lower values â†’ more deterministic output.

    model : str

        OpenAI model to use.

 

    Returns

    -------

    str

        A single, natural English sentence ending with proper punctuation.

    """

    # 1) Prepare the instruction; we specify constraints to preserve semantics.

    system = (

        "You are a precise sign-language translator. "

        "Convert gloss tokens to a natural English sentence with correct grammar, "

        "articles, tense, and punctuation. Do not add new facts beyond what is implied "

        "by the glosses. Preserve named entities and numbers exactly. Output only the sentence."

    )

 

    # 2) Provide a couple of tiny few-shot examples to stabilize style.

    examples = [

        {

            "gloss": ["YESTERDAY", "STORE", "I", "GO"],

            "english": "I went to the store yesterday."

        },

        {

            "gloss": ["TODAY", "SCHOOL", "WE", "MEET", "AFTERNOON"],

            "english": "We will meet at school this afternoon."

        }

    ]

 

    # 3) Compose user content with the current tokens and optional context.

    user_lines = []

    if context_hint:

        user_lines.append(f"Context: {context_hint}")

    user_lines.append("Gloss tokens: " + " ".join(gloss_tokens))

    user_lines.append("Return a single complete English sentence.")

    user_prompt = "\n".join(user_lines)

 

    # 4) Build an input string combining instruction + few-shots + current request.

    #    Using the Responses API with `input` keeps things simple.

    few_shot_text = "\n\n".join([

        f"Example gloss: {' '.join(ex['gloss'])}\nExample English: {ex['english']}"

        for ex in examples

    ])

 

    full_input = (

        f"System: {system}\n\n"

        f"{few_shot_text}\n\n"

        f"Now, translate the following into one fluent English sentence.\n"

        f"{user_prompt}"

    )

 

    # 5) Call the model. Keep temperature low for consistency.

    resp = client.responses.create(

        model=model,

        input=full_input,

        temperature=temperature

    )

 

    # 6) Extract the plain text. The SDK exposes output_text for convenience.

    sentence = resp.output_text.strip()

 

    # 7) Ensure final punctuation.

    if not sentence.endswith(('.', '!', '?')):

        sentence += "."

    return sentence
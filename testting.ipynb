{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48d1cd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, TimeDistributed, Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2e664e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1340f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv.cvtColor(image, cv.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "420fde41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION,\n",
    "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                             )\n",
    "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61050cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints(results):\n",
    "    face = np.array([[res.x, res.y, res.z] for res in results.face_landmarks.landmark]).flatten() if results.face_landmarks else np.zeros(468*3)\n",
    "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
    "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
    "    return np.concatenate([face, lh, rh])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d871b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/home/smayan/Desktop/ASL/dataset/SL'\n",
    "sequence_length = 30\n",
    "min_sequences_per_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbbe1ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [\n",
    "    'a', 'about', 'again', 'all', 'also', 'always', 'and', 'angry', 'animal', 'answer', \n",
    "    'apple', 'ask', 'baby', 'bad', 'bathroom', 'beautiful', 'because', 'bed', 'before', \n",
    "    'big', 'book', 'boy', 'brother', 'but', 'buy', 'bye', 'call', 'can', 'car', 'cat', \n",
    "    'city', 'class', 'clean', 'clothes', 'cold', 'college', 'color', 'come', 'computer', \n",
    "    'cook', 'dad', 'day', 'deaf', 'different', 'doctor', 'dog', 'done', \"don't want\", \n",
    "    'down', 'drink', 'eat', 'eight', 'enough', 'family', 'fast', 'father', 'feel', \n",
    "    'find', 'fine', 'finish', 'first', 'five', 'food', 'for', 'four', 'friend', 'from', \n",
    "    'get', 'girl', 'give', 'go', 'good', 'goodbye', 'happy', 'hard', 'have', \n",
    "    'head', 'hearing', 'hello', 'help', 'her', 'here', 'home', 'hospital', 'hot', \n",
    "    'house', 'how', 'hungry', 'i', 'if', 'in', 'know', 'language', 'last', 'later', \n",
    "    'learn', 'letter', 'like', 'little bit', 'live', 'look at', 'love', 'make', 'man', \n",
    "    'many', 'me', 'meet', 'milk', 'mom', 'money', 'month', 'more', 'morning', 'mother', \n",
    "    'movie', 'music', 'my', 'name', 'need', 'never', 'new', 'nice', 'night', 'nine', \n",
    "    'no', 'not', 'now', 'old', 'on', 'one', 'open', 'orange', 'our', 'out', 'people', \n",
    "    'phone', 'play', 'please', 'put', 'question', 'read', 'ready', 'red', 'right', 'sad', \n",
    "    'same', 'say', 'school', 'see', 'seven', 'she', 'shirt', 'shoes', 'show', 'sick', \n",
    "    'sign', 'sign language', 'sister', 'sit', 'six', 'sleep', 'slow', 'small', 'sorry', \n",
    "    'stand', 'start', 'stop', 'store', 'story', 'student', 'study', 'talk', 'teach', \n",
    "    'teacher', 'tell', 'ten', 'thank you', 'that']\n",
    "# 'the', 'their', 'they', 'thing', \n",
    "#     'think', 'thirsty', 'this', 'three', 'time', 'tired', 'to', 'today', 'tomorrow', \n",
    "#     'two', 'understand', 'up', 'use', 'wait', 'walk', 'want', 'water', 'way', \n",
    "#     'we', 'wear', 'week', 'what', 'when', 'where', 'which', 'white', 'who', 'why', \n",
    "#     'will', 'with', 'woman', 'word', 'work', 'world', 'write', 'wrong', 'year', 'yellow', \n",
    "#     'yes', 'yesterday', 'you', 'your'\n",
    "# ]\n",
    "label_map = {label: num for num, label in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "459feb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('label_map.npy', label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0eab066b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 0,\n",
       " 'about': 1,\n",
       " 'again': 2,\n",
       " 'all': 3,\n",
       " 'also': 4,\n",
       " 'always': 5,\n",
       " 'and': 6,\n",
       " 'angry': 7,\n",
       " 'animal': 8,\n",
       " 'answer': 9,\n",
       " 'apple': 10,\n",
       " 'ask': 11,\n",
       " 'baby': 12,\n",
       " 'bad': 13,\n",
       " 'bathroom': 14,\n",
       " 'beautiful': 15,\n",
       " 'because': 16,\n",
       " 'bed': 17,\n",
       " 'before': 18,\n",
       " 'big': 19,\n",
       " 'book': 20,\n",
       " 'boy': 21,\n",
       " 'brother': 22,\n",
       " 'but': 23,\n",
       " 'buy': 24,\n",
       " 'bye': 25,\n",
       " 'call': 26,\n",
       " 'can': 27,\n",
       " 'car': 28,\n",
       " 'cat': 29,\n",
       " 'city': 30,\n",
       " 'class': 31,\n",
       " 'clean': 32,\n",
       " 'clothes': 33,\n",
       " 'cold': 34,\n",
       " 'college': 35,\n",
       " 'color': 36,\n",
       " 'come': 37,\n",
       " 'computer': 38,\n",
       " 'cook': 39,\n",
       " 'dad': 40,\n",
       " 'day': 41,\n",
       " 'deaf': 42,\n",
       " 'different': 43,\n",
       " 'doctor': 44,\n",
       " 'dog': 45,\n",
       " 'done': 46,\n",
       " \"don't want\": 47,\n",
       " 'down': 48,\n",
       " 'drink': 49,\n",
       " 'eat': 50,\n",
       " 'eight': 51,\n",
       " 'enough': 52,\n",
       " 'family': 53,\n",
       " 'fast': 54,\n",
       " 'father': 55,\n",
       " 'feel': 56,\n",
       " 'find': 57,\n",
       " 'fine': 58,\n",
       " 'finish': 59,\n",
       " 'first': 60,\n",
       " 'five': 61,\n",
       " 'food': 62,\n",
       " 'for': 63,\n",
       " 'four': 64,\n",
       " 'friend': 65,\n",
       " 'from': 66,\n",
       " 'get': 67,\n",
       " 'girl': 68,\n",
       " 'give': 69,\n",
       " 'go': 70,\n",
       " 'good': 71,\n",
       " 'goodbye': 72,\n",
       " 'happy': 73,\n",
       " 'hard': 74,\n",
       " 'have': 75,\n",
       " 'head': 76,\n",
       " 'hearing': 77,\n",
       " 'hello': 78,\n",
       " 'help': 79,\n",
       " 'her': 80,\n",
       " 'here': 81,\n",
       " 'home': 82,\n",
       " 'hospital': 83,\n",
       " 'hot': 84,\n",
       " 'house': 85,\n",
       " 'how': 86,\n",
       " 'hungry': 87,\n",
       " 'i': 88,\n",
       " 'if': 89,\n",
       " 'in': 90,\n",
       " 'know': 91,\n",
       " 'language': 92,\n",
       " 'last': 93,\n",
       " 'later': 94,\n",
       " 'learn': 95,\n",
       " 'letter': 96,\n",
       " 'like': 97,\n",
       " 'little bit': 98,\n",
       " 'live': 99,\n",
       " 'look at': 100,\n",
       " 'love': 101,\n",
       " 'make': 102,\n",
       " 'man': 103,\n",
       " 'many': 104,\n",
       " 'me': 105,\n",
       " 'meet': 106,\n",
       " 'milk': 107,\n",
       " 'mom': 108,\n",
       " 'money': 109,\n",
       " 'month': 110,\n",
       " 'more': 111,\n",
       " 'morning': 112,\n",
       " 'mother': 113,\n",
       " 'movie': 114,\n",
       " 'music': 115,\n",
       " 'my': 116,\n",
       " 'name': 117,\n",
       " 'need': 118,\n",
       " 'never': 119,\n",
       " 'new': 120,\n",
       " 'nice': 121,\n",
       " 'night': 122,\n",
       " 'nine': 123,\n",
       " 'no': 124,\n",
       " 'not': 125,\n",
       " 'now': 126,\n",
       " 'old': 127,\n",
       " 'on': 128,\n",
       " 'one': 129,\n",
       " 'open': 130,\n",
       " 'orange': 131,\n",
       " 'our': 132,\n",
       " 'out': 133,\n",
       " 'people': 134,\n",
       " 'phone': 135,\n",
       " 'play': 136,\n",
       " 'please': 137,\n",
       " 'put': 138,\n",
       " 'question': 139,\n",
       " 'read': 140,\n",
       " 'ready': 141,\n",
       " 'red': 142,\n",
       " 'right': 143,\n",
       " 'sad': 144,\n",
       " 'same': 145,\n",
       " 'say': 146,\n",
       " 'school': 147,\n",
       " 'see': 148,\n",
       " 'seven': 149,\n",
       " 'she': 150,\n",
       " 'shirt': 151,\n",
       " 'shoes': 152,\n",
       " 'show': 153,\n",
       " 'sick': 154,\n",
       " 'sign': 155,\n",
       " 'sign language': 156,\n",
       " 'sister': 157,\n",
       " 'sit': 158,\n",
       " 'six': 159,\n",
       " 'sleep': 160,\n",
       " 'slow': 161,\n",
       " 'small': 162,\n",
       " 'sorry': 163,\n",
       " 'stand': 164,\n",
       " 'start': 165,\n",
       " 'stop': 166,\n",
       " 'store': 167,\n",
       " 'story': 168,\n",
       " 'student': 169,\n",
       " 'study': 170,\n",
       " 'talk': 171,\n",
       " 'teach': 172,\n",
       " 'teacher': 173,\n",
       " 'tell': 174,\n",
       " 'ten': 175,\n",
       " 'thank you': 176,\n",
       " 'that': 177}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba0ea86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "354a7620",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be66c26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('/media/smayan/500GB SSD/X.npy')\n",
    "y = np.load('/media/smayan/500GB SSD/y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f2a2a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.shape[2]\n",
    "X = X.reshape(X.shape[0], X.shape[1], num_features, 1)\n",
    "\n",
    "y_categorical = to_categorical(y, num_classes=len(actions))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_categorical, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bb3937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.squeeze(-1)  # Now shape = (6314, 30, 1530)\n",
    "X_test  = X_test.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51cb3edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "I0000 00:00:1755701043.487363   36174 gl_context_egl.cc:85] Successfully initialized EGL. Major : 1 Minor: 5\n",
      "I0000 00:00:1755701043.531717   43994 gl_context.cc:369] GL version: 3.2 (OpenGL ES 3.2 NVIDIA 570.172.08), renderer: NVIDIA GeForce RTX 4070 SUPER/PCIe/SSE2\n",
      "W0000 00:00:1755701043.573657   43974 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755701043.592137   43970 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755701043.593034   43975 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755701043.593055   43979 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755701043.593622   43971 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755701043.598311   43966 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755701043.599277   43969 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1755701043.608252   43990 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# Load trained model and label map\n",
    "model = tf.keras.models.load_model('/home/smayan/Desktop/ASL/main_wsl_model_20250819-203608.h5')\n",
    "label_map = np.load('/home/smayan/Desktop/ASL/label_map.npy', allow_pickle=True).item()\n",
    "actions = list(label_map.keys())\n",
    "\n",
    "# Variables for prediction\n",
    "sequence = []\n",
    "sequence_length = 30\n",
    "threshold = 0.7\n",
    "\n",
    "# Start webcam / video\n",
    "cap = cv.VideoCapture('ssvid.net---How-to-sign-I-m-the-doctor_1080p.mp4')\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize for consistency\n",
    "        frame = cv.resize(frame, (640, 480))\n",
    "\n",
    "        # Detection\n",
    "        image, results = mediapipe_detection(frame, holistic)\n",
    "\n",
    "        # Draw landmarks\n",
    "        draw_styled_landmarks(image, results)\n",
    "\n",
    "        # Extract keypoints (same as training)\n",
    "        keypoints = extract_keypoints(results)\n",
    "\n",
    "        # Append to sequence\n",
    "        sequence.append(keypoints)\n",
    "        sequence = sequence[-sequence_length:]\n",
    "\n",
    "        if len(sequence) == sequence_length:\n",
    "            input_seq = np.expand_dims(sequence, axis=0)   # shape (1, 30, 1530)\n",
    "\n",
    "            # Predict\n",
    "            res = model.predict(input_seq, verbose=0)[0]\n",
    "            predicted_action = actions[np.argmax(res)]\n",
    "            confidence = np.max(res)\n",
    "\n",
    "            # Show prediction if above threshold\n",
    "            if confidence > threshold:\n",
    "                cv.putText(image, f'{predicted_action}: {confidence:.2f}',\n",
    "                           (10, 50), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            # Show probabilities\n",
    "            for i, (action, prob) in enumerate(zip(actions, res)):\n",
    "                y_pos = 100 + i * 30\n",
    "                cv.rectangle(image, (10, y_pos), (int(prob * 300) + 10, y_pos + 25), (0, 255, 0), -1)\n",
    "                cv.putText(image, f'{action}: {prob:.2f}', (15, y_pos + 18),\n",
    "                           cv.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "        # Show output\n",
    "        cv.imshow('ASL Inference', image)\n",
    "\n",
    "        # Quit\n",
    "        if cv.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6804f8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
